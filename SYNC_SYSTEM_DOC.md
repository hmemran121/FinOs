# FinOS Sync System: Comprehensive Technical Audit & Scalability Report

এই রিপোর্টে আমাদের সিঙ্ক সিস্টেমের বর্তমান অবস্থা, ব্যবহৃত প্রযুক্তি, কার্যপদ্ধতি এবং লক্ষ্যাধিক ইউজারের ক্ষেত্রে সম্ভাব্য ঝুঁকি ও সমাধান বিস্তারিতভাবে আলোচনা করা হয়েছে।

---

## ১. প্রযুক্তিগত ওভারভিউ (Technology Stack)

আমাদের সিঙ্ক সিস্টেমটি একটি **Hybrid Peer-to-Server** আর্কিটেকচার মেনে চলে, যা সিঙ্ক করার সময় ডেটা ইন্টিগ্রিটিকে সর্বোচ্চ গুরুত্ব দেয়।

*   **Local Engine:** `Capacitor SQLite` (Native Bridge) - এটি ফোনে একটি পূর্ণাঙ্গ SQL ডেটাবেজ হিসেবে কাজ করে।
*   **Cloud Backend:** `Supabase` (Open-source Firebase alternative) - আমরা এখানে `PostgreSQL` ডেটাবেজ, `Auth` এবং `Realtime` (WebSockets) ব্যবহার করছি।
*   **Protocol:** **USAP (Ultra-Strict Authority Protocol)** - এটি আমাদের নিজস্ব একটি লজিক গেট যা সার্ভার টোকেন ছাড়া ফোনে কোনো ডেটা পুল করতে দেয় না।
*   **Conflict Resolution:** **Precision-LWW (Last Write Wins)** - মিলি-সেকেন্ড লেভেল টাইমস্ট্যাম্প ব্যবহার করে কনফ্লিক্ট হ্যান্ডেল করা হয়।

---

## ২. কার্যপদ্ধতি (Operational Logic)

সিঙ্ক ইঞ্জিনটি মূলত ৩টি ধাপে কাজ করে:

### ধাপে ১: Authority Verification (টোকেন যাচাই)
অ্যাপ চালু হওয়ার সাথে সাথে এটি সার্ভার থেকে `user_sync_token` সংগ্রহ করার চেষ্টা করে (সর্বোচ্চ ১০ বার চেষ্টা)। যদি সার্ভারের টোকেন ফোনের টোকেনের চেয়ে বড় হয় (`Server > Local`), শুধুমাত্র তখনই ডেটা ডাউনলোড শুরু হয়। এর ফলে কোনো অপ্রয়োজনীয় কোয়েরি (Unnecessary Query) হয় না।

### ধাপে ২: Tiered Delta Sync (ধাপে ধাপে সিঙ্ক)
ডেটা ডিপেন্ডেন্সির কারণে আমরা ৩টি টবিয়ারে সিঙ্ক করি:
*   **Tier 1 (Core):** `wallets` (সবচেয়ে আগে সিঙ্ক হয়)।
*   **Tier 2 (Dependent):** `channels`, `categories_user` ইত্যাদি।
*   **Tier 3 (Activity):** `transactions` এবং `plans` (সবার শেষে)।
এর ফলে 'Foreign Key Constraint' এরর হওয়ার সম্ভাবনা থাকে না।

### ধাপে ৩: Nano-Pulse Update (রিয়েল-টাইম)
Supabase WebSocket ব্যবহার করে আমরা 'Realtime listeners' লাগিয়েছি। যখনই সার্ভারে কোনো পরিবর্তন হয়, অ্যাপে একটি **Nano-Pulse** সিগন্যাল আসে এবং অ্যাপ সাথে সাথে সিঙ্ক শুরু করে।

---

## ৩. লক্ষ্যাধিক ইউজারের ক্ষেত্রে স্কেলেবিলিটি ও ঝুঁকি (Scalability & Risks)

আমাদের বর্তমান সিস্টেমটি ১ লক্ষ বা তার বেশি ইউজারের জন্য তৈরি করার ক্ষেত্রে কিছু চ্যালেঞ্জ রয়েছে:

### ঝুঁকি ১: Metadata Fetch Bottleneck
বর্তমানে প্রতিবার অ্যাপ খোলার সময় এবং নেটওয়ার্ক ফিরে এলে হার্ট-বিট চেক করা হয়। যদি ১ লক্ষ ইউজার একই সাথে অ্যাপ খোলে, তবে Supabase API-তে প্রতি সেকেন্ডে হাজার হাজার রিকোয়েস্ট পড়বে যা ডেটাবেজ কানেকশন লিমিট অতিক্রম করতে পারে।

### ঝুঁকি ২: WebSocket Connection Limit
Supabase এর ফ্রি বা ছোট প্ল্যানগুলোতে একসাথে কানেক্টেড থাকতে পারে এমন ইউজারের সংখ্যা সীমিত (যেমন ৫০০০-১০০০ জন)। ১ লক্ষ ইউজারের ক্ষেত্রে আমাদের **Supabase Enterprise** বা বড় প্রো-প্ল্যানে যেতে হবে অথবা WebSockets এর বিকল্প হিসেবে 'HTTP Long Polling' বা 'Periodic Batch' এ ফিরে আসতে হবে।

### ঝুঁকি ৩: Transaction Table Locking
ইউজার যখন হাজার হাজার ট্রানজেকশন একসাথে আপলোড করবেন, তখন Postgres এর `Row-level locking` সিস্টেম বড় কোনো আপডেটের সময় অন্য সিঙ্ক রিকোয়েস্টকে সাময়িকভাবে স্লো করে দিতে পারে।

---

## ৪. ভবিষ্যৎ উন্নয়ন পরিকল্পনা (Roadmap for Growth)

১০ লক্ষ ইউজারের জন্য আমরা নিম্নলিখিত পদক্ষেপগুলো নিতে পারি:

১. **Batching Optimization:** প্রতিটি ট্রানজেকশন আলাদাভাবে না পাঠিয়ে ২০-৩০টি ট্রানজেকশন একটি প্যাকেজে সিঙ্ক করা।
২. **Edge Functions:** কনফ্লিক্ট রেজোলিউশন লজিকটি সরাসরি ফোন থেকে না করে Supabase Edge Functions (Deno) দিয়ে করা।
৩. **Read Replicas:** মেটাডেটা চেক করার জন্য আলাদা 'Read-Only' ডেটাবেজ ব্যবহার করা যাতে মূল রাইটিং ডেটাবেজে চাপ না পড়ে।
৪. **Redis Caching:** গ্লোবাল অথরিটি টোকেনগুলো Redis-এ ক্যাশ করা যাতে ডেটাবেজে বারবার হিট না হয়।

---

**উপসংহার:**
বর্তমান সিস্টেমটি অত্যন্ত সুরক্ষিত (Secure) এবং ইফিশিয়েন্ট। তবে ইউজারের সংখ্যা উল্লেখযোগ্যভাবে বাড়লে আমাদের অবকাঠামো ব্যাকএন্ড (Server-side) লেভেলে আপগ্রেড করতে হবে। ফোনের অ্যাপের লজিক (USAP) ১ লক্ষ ইউজারের চাপের মধ্যেও ডেটা কারাপশন ছাড়াই কাজ করতে সক্ষম।
